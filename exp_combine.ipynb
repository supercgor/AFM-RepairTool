{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/d/gitfile/AFM-RepairTool'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from exp_process_funcs_block import *\n",
    "from src.poscar import poscar\n",
    "import einops\n",
    "dataset = \"../data/middle\"\n",
    "model_name = \"unet_tune_v0\"\n",
    "use_poscar = False\n",
    "dics = os.listdir(f\"{dataset}/combine_afm\")\n",
    "#dics = [\"pls2\"]\n",
    "#dics = [\"HDA3\", \"HDA4\", \"HDA5\", \"HDA6\", \"HDA7\", \"HDA8\", \"ss0\", \"exp91\"]\n",
    "# dics = [\"exp91\"] \n",
    "# readme = json.load(open(f\"{dataset}/combine_afm/{dic}/readme.json\"))\n",
    "# N_exp = readme[\"imgs\"]\n",
    "# L_exp, L_step, L_tar, stride = read_slide_info(f\"{dataset}/afm/{dic}_cut_info.txt\")\n",
    "# L_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{dataset}/combine\", exist_ok=True)\n",
    "os.makedirs(f\"{dataset}/combine/{model_name}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52 52]\n",
      "[52 39]\n",
      "[56 41]\n",
      "[39 49]\n",
      "[52 52]\n",
      "[36 71]\n",
      "[90 90]\n",
      "[52 61]\n"
     ]
    }
   ],
   "source": [
    "for dic in dics:\n",
    "    readme = json.load(open(f\"{dataset}/combine_afm/{dic}/readme.json\"))\n",
    "    N_exp = readme[\"imgs\"]\n",
    "    L_exp, L_step, L_tar, stride = read_slide_info(f\"{dataset}/afm/{dic}_cut_info.txt\")\n",
    "\n",
    "    ldirs0 = os.listdir(f\"{dataset}/afm\")\n",
    "    regex = re.compile(f\"{dic}_\" + r'(-?\\d+)_(-?\\d+)_(-?\\d+)_(-?\\d+)')\n",
    "    ldirs = [i for i in ldirs0 if regex.match(i)]\n",
    "    flag_list = [np.array(l.split('_')[1:]).astype(int) for l in ldirs]\n",
    "    file_list = [f\"{dataset}/result/{model_name}/{l}.poscar\" for l in ldirs]\n",
    "    Cubic_out = combine_cell_pos(file_list,flag_list,L_exp,L_tar,stride, 2.5 / 32)\n",
    "    path_prediction = f\"{dataset}/combine/{model_name}/{dic}.poscar\"\n",
    "\n",
    "    Cubic_out = einops.rearrange(torch.from_numpy(Cubic_out), \"H W D (E C)-> D H W E C\", C = 4)[...,(3,2,0,1)]\n",
    "    point_dict = poscar.box2pos(Cubic_out, real_size = (3.0, L_exp[1] * 10, L_exp[0] * 10), threshold= 0.5, sort = False)\n",
    "    poscar.pos2poscar(f\"{dataset}/combine/{model_name}/{dic}.poscar\", point_dict, real_size=(3.0, L_exp[1] * 10, L_exp[0] * 10))\n",
    "    \n",
    "    del Cubic_out\n",
    "    \n",
    "    file_list_npy = [f\"{dataset}/npy/{model_name}/{l}.npy\" for l in ldirs]\n",
    "    Cubic_out_npy = combine_cell(file_list_npy,flag_list,L_exp,L_tar,stride, 2.5 / 32)\n",
    "    path_prediction_npy = f\"{dataset}/combine/{model_name}/{dic}.npy\"\n",
    "\n",
    "    Cubic_out_npy = einops.rearrange(torch.from_numpy(Cubic_out_npy), \"H W D (E C)-> D H W E C\", C = 4)[...,(3,2,0,1)]\n",
    "    np.save(f\"{dataset}/combine/{model_name}/{dic}.npy\", Cubic_out_npy)\n",
    "    point_dict = poscar.box2pos(Cubic_out_npy, real_size = (3.0, L_exp[1] * 10, L_exp[0] * 10), threshold= 0.5, sort = True)\n",
    "    poscar.pos2poscar(f\"{dataset}/combine/{model_name}/{dic}_npy.poscar\", point_dict, real_size=(3.0, L_exp[1] * 10, L_exp[0] * 10))\n",
    "\n",
    "    # positions_pred = target2positions(Cubic_out, info, ['O', 'H'],0.63, True)\n",
    "    # positions_pred = target2positions_O(Cubic_out, info, ['O', 'H'],0.63, False) # use the restrict rules O:H 1:2\n",
    "    # positions2poscar(positions_pred, info, path_prediction)\n",
    "\n",
    "    # positions_pred_npy = target2positions_O(Cubic_out_npy, info, ['O', 'H'],0.63, True) # use the restrict rules O:H 1:2\n",
    "    # positions2poscar(positions_pred_npy, info, path_prediction_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
